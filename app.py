# app.py
from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import time
import threading
import requests
import torch
from dotenv import load_dotenv
from transformers import BertTokenizer, BertForSequenceClassification

# -------------------- ç’°å¢ƒèˆ‡å¸¸æ•¸ --------------------
load_dotenv()

OCR_API_KEY = os.environ.get("OCR_API_KEY")
HF_REPO = os.environ.get("HF_REPO")          # å¯é¸ï¼šHugging Face æ¨¡å‹å€‰åº«ï¼ˆä¾‹å¦‚ "yourname/new-bert-scam-model"ï¼‰
HF_TOKEN = os.environ.get("HF_TOKEN")        # å¯é¸ï¼šç§æœ‰å€‰åº«çš„å­˜å– token

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
BERT_MODEL_PATH = os.path.join(BASE_DIR, "new_bert_scam_model")  # ä½¿ç”¨çµ•å°è·¯å¾‘é¿å…éƒ¨ç½²æ™‚å·¥ä½œç›®éŒ„è®Šå‹•

# -------------------- æª”æ¡ˆå¥æª¢å·¥å…· --------------------
def _has_any(path, names):
    return any(os.path.exists(os.path.join(path, n)) for n in names)

def check_model_folder(path):
    """æª¢æŸ¥æœ¬æ©Ÿæ¨¡å‹è³‡æ–™å¤¾æ˜¯å¦é½Šå‚™ï¼Œå›å‚³ç¼ºå°‘æ¸…å–®ï¼ˆç©ºæ¸…å–® = OKï¼‰ã€‚"""
    missing = []
    tokenizer_ok = _has_any(path, ["tokenizer.json", "vocab.txt"])
    model_ok = _has_any(path, ["pytorch_model.bin", "model.safetensors"])

    for fname in ["config.json", "special_tokens_map.json", "tokenizer_config.json"]:
        if not os.path.exists(os.path.join(path, fname)):
            missing.append(fname)
    if not tokenizer_ok:
        missing.append("tokenizer.json | vocab.txtï¼ˆè‡³å°‘å…¶ä¸€ï¼‰")
    if not model_ok:
        missing.append("pytorch_model.bin | model.safetensorsï¼ˆè‡³å°‘å…¶ä¸€ï¼‰")

    return missing

def _hf_load_tokenizer(repo, token):
    """ç›¸å®¹ä¸åŒ transformers ç‰ˆæœ¬çš„ token åƒæ•¸åç¨±ã€‚"""
    try:
        return BertTokenizer.from_pretrained(repo, token=token) if token else BertTokenizer.from_pretrained(repo)
    except TypeError:
        return BertTokenizer.from_pretrained(repo, use_auth_token=token) if token else BertTokenizer.from_pretrained(repo)

def _hf_load_model(repo, token):
    """ç›¸å®¹ä¸åŒ transformers ç‰ˆæœ¬çš„ token åƒæ•¸åç¨±ã€‚"""
    try:
        return BertForSequenceClassification.from_pretrained(repo, token=token) if token else BertForSequenceClassification.from_pretrained(repo)
    except TypeError:
        return BertForSequenceClassification.from_pretrained(repo, use_auth_token=token) if token else BertForSequenceClassification.from_pretrained(repo)

# -------------------- æ¨¡å‹å°è£ --------------------
class SpamDetector:
    """
    å°è£æ¨¡å‹è¼‰å…¥èˆ‡é æ¸¬ï¼ŒåŸ·è¡Œç·’å®‰å…¨ã€‚
    """
    _lock = threading.Lock()

    def __init__(self):
        self.tokenizer = None
        self.bert_model = None
        self.model_loaded = False
        print("âœ… SpamDetector å¯¦ä¾‹å·²å»ºç«‹ï¼ŒBERT æ¨¡å‹å°‡åœ¨é¦–æ¬¡è«‹æ±‚æ™‚è¼‰å…¥ã€‚")

    def _load_model(self):
        """åªåœ¨éœ€è¦æ™‚è¼‰å…¥ä¸€æ¬¡ã€‚"""
        if self.model_loaded:
            return

        start_time = time.time()
        print("ğŸš€ åµæ¸¬åˆ°é¦–æ¬¡è«‹æ±‚ï¼Œé–‹å§‹è¼‰å…¥ BERT æ¨¡å‹...")

        with self._lock:
            if self.model_loaded:
                return

            # 1) æœ¬æ©Ÿæ¨¡å‹ï¼ˆåªè®€æœ¬åœ°æª”ï¼‰
            try:
                missing = check_model_folder(BERT_MODEL_PATH)
                if missing:
                    raise RuntimeError(
                        f"æ¨¡å‹è³‡æ–™å¤¾ç¼ºå°‘å¿…è¦æª”æ¡ˆï¼š{missing}ï¼›è·¯å¾‘ï¼š{BERT_MODEL_PATH}ã€‚"
                        "å¤šåŠæ˜¯ Git LFS æŒ‡æ¨™æª”æœªæ‹‰ä¸‹ä¾†æˆ–æª”æ¡ˆæœªéš¨ç¨‹å¼éƒ¨ç½²ã€‚"
                    )

                self.tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, local_files_only=True)
                self.bert_model = BertForSequenceClassification.from_pretrained(BERT_MODEL_PATH, local_files_only=True)

                self.model_loaded = True
                print("âœ… BERT æ¨¡å‹è¼‰å…¥æˆåŠŸï¼ˆæœ¬æ©Ÿæª”ï¼‰")
            except Exception as e_local:
                print(f"âš ï¸ æœ¬æ©Ÿæ¨¡å‹è¼‰å…¥å¤±æ•—ï¼š{e_local}")

                # 2) Hugging Face å¾Œå‚™ï¼ˆå¯é¸ï¼šæœ‰è¨­å®š HF_REPO æ‰æœƒè§¸ç™¼ï¼‰
                if HF_REPO:
                    try:
                        print(f"ğŸ” å˜—è©¦å¾ Hugging Face è¼‰å…¥ï¼š{HF_REPO}")
                        self.tokenizer = _hf_load_tokenizer(HF_REPO, HF_TOKEN)
                        self.bert_model = _hf_load_model(HF_REPO, HF_TOKEN)
                        self.model_loaded = True
                        print("âœ… BERT æ¨¡å‹è¼‰å…¥æˆåŠŸï¼ˆHugging Face å¾Œå‚™ï¼‰")
                    except Exception as e_hf:
                        print(f"âŒ HF å¾Œå‚™ä¹Ÿå¤±æ•—ï¼š{e_hf}")

        end_time = time.time()
        print(f"ğŸ‘ æ¨¡å‹è¼‰å…¥å®Œç•¢ï¼è€—æ™‚: {end_time - start_time:.2f} ç§’")

    def analyze(self, text: str):
        """åŸ·è¡Œæ¨¡å‹åˆ†æã€‚"""
        self._load_model()

        if not self.model_loaded or not self.bert_model:
            return {'error': 'æ¨¡å‹æœªèƒ½æˆåŠŸè¼‰å…¥ï¼Œç„¡æ³•åˆ†æ'}

        try:
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                truncation=True,
                padding=True,
                max_length=128
            )
            with torch.no_grad():
                outputs = self.bert_model(**inputs)

            logits = outputs.logits
            probabilities = torch.softmax(logits, dim=-1)
            spam_score = probabilities[0][1].item()

            confidence_percentage = f"{spam_score * 100:.1f}%"
            if spam_score >= 0.5:
                display_text = f"ç¶“åµæ¸¬å¾Œç™¼ç¾æ‚¨çš„è¨Šæ¯æœ‰ {confidence_percentage} ç‚ºè©é¨™ï¼Œè«‹æ’¥æ‰“165åè©é¨™å°ˆç·šã€‚"
                is_scam = True
            else:
                display_text = f"ç¶“åµæ¸¬å¾Œï¼Œæ­¤è¨Šæ¯ç‚ºè©é¨™çš„å¯èƒ½æ€§ç‚º {confidence_percentage}ï¼Œé¢¨éšªè¼ƒä½ã€‚"
                is_scam = False

            print(f"æœ€çµ‚è¼¸å‡ºæ–‡å­—: {display_text}")

            return {
                "display_text": display_text,
                "is_scam": is_scam,
                "confidence_percentage": confidence_percentage,
                "raw_score": round(spam_score, 4),
                "original_text": text
            }

        except Exception as e:
            print(f"âŒ BERT é æ¸¬éŒ¯èª¤: {e}")
            return {'error': 'BERT æ¨¡å‹é æ¸¬æ™‚ç™¼ç”ŸéŒ¯èª¤'}

# -------------------- OCR åŠŸèƒ½ï¼ˆå¯é¸ï¼‰ --------------------
def perform_ocr(image_file):
    """åŸ·è¡Œ OCR è™•ç†ï¼Œè¿”å› (æ–‡å­—, None) æˆ– (None, éŒ¯èª¤ JSON)ã€‚"""
    if not OCR_API_KEY:
        return None, {'error': 'OCR_API_KEY_MISSING'}

    try:
        ext = os.path.splitext(image_file.filename)[1].lower() or '.jpg'
        mime_types = {
            '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg',
            '.png': 'image/png',   '.bmp': 'image/bmp',
            '.gif': 'image/gif'
        }
        mime = mime_types.get(ext, 'image/jpeg')

        # é‡ç½®æª”æ¡ˆæŒ‡æ¨™ï¼Œé¿å…è®€ä¸åˆ°å…§å®¹
        image_file.seek(0)

        resp = requests.post(
            'https://api.ocr.space/parse/image',
            files={'filename': ('image' + ext, image_file, mime)},
            data={'apikey': OCR_API_KEY, 'language': 'cht'},
            timeout=30
        )
        if resp.status_code != 200:
            return None, {'error': f'OCR API è«‹æ±‚å¤±æ•—: HTTP {resp.status_code}'}

        result = resp.json()
        if result.get('IsErroredOnProcessing'):
            details = result.get('ErrorMessage') or result.get('ErrorDetails') or 'unknown'
            return None, {'error': 'OCR_API_ERROR', 'details': details}

        if not result.get('ParsedResults'):
            return None, {'error': 'OCR ç„¡æ³•å¾åœ–ç‰‡ä¸­æå–æ–‡å­—'}

        extracted_text = result['ParsedResults'][0].get('ParsedText', '').strip()
        return extracted_text, None

    except requests.exceptions.Timeout:
        return None, {'error': 'OCR API è«‹æ±‚è¶…æ™‚'}
    except requests.exceptions.RequestException as e:
        return None, {'error': f'OCR API è«‹æ±‚éŒ¯èª¤: {str(e)}'}
    except Exception as e:
        return None, {'error': f'OCR è™•ç†æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {str(e)}'}

# -------------------- Flask å…¥å£ --------------------
app = Flask(__name__)
CORS(app)
detector_instance = SpamDetector()

@app.route('/', methods=['GET'])
def health_check():
    return jsonify({"status": "OK", "message": "åè©é¨™ API æ­£å¸¸é‹ä½œ"}), 200

# é™¤éŒ¯è·¯ç”±ï¼šç”¨ä¾†ç¢ºèªä¼ºæœå™¨ä¸Šæ¨¡å‹æª”æ˜¯å¦çœŸçš„å­˜åœ¨ï¼ˆä¿®å¥½å¾Œå¯ç§»é™¤ï¼‰
@app.route('/_debug/files', methods=['GET'])
def debug_files():
    try:
        files = {}
        if os.path.isdir(BERT_MODEL_PATH):
            for name in os.listdir(BERT_MODEL_PATH):
                p = os.path.join(BERT_MODEL_PATH, name)
                try:
                    files[name] = os.path.getsize(p)
                except OSError:
                    files[name] = None
        else:
            files = None

        return jsonify({
            "base_dir": BASE_DIR,
            "model_path": BERT_MODEL_PATH,
            "exists": os.path.isdir(BERT_MODEL_PATH),
            "files_with_size_bytes": files
        }), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/analyze-all', methods=['POST'])
def analyze_all():
    """æ¥æ”¶ç´”æ–‡å­—æˆ–åœ–ç‰‡ + æ–‡å­—ï¼Œä¸¦å‘¼å«æ¨¡å‹åšåˆ†æã€‚"""
    try:
        image_file = request.files.get('image', None)
        text_input = request.form.get('text', '').strip()
        extracted_text = ''

        # åœ–ç‰‡ OCRï¼ˆå¯é¸ï¼‰
        if image_file:
            text_from_img, ocr_err = perform_ocr(image_file)
            if ocr_err:
                return jsonify(ocr_err), 500
            extracted_text = text_from_img or ''

            # ä½å“è³ªåœ–ç‰‡ç›´æ¥å›å ±
            if len(extracted_text) < 10:
                return jsonify({'error': 'åœ–ç‰‡è¾¨è­˜ä¸æ¸…ï¼Œè«‹é‡æ–°ä¸Šå‚³æ›´æ¸…æ™°çš„åœ–ç‰‡'}), 400

        # åˆä½µè¼¸å…¥æ–‡å­—
        full_text = f"{extracted_text} {text_input}".strip()
        if not full_text:
            return jsonify({'error': 'æœªæä¾›æœ‰æ•ˆæ–‡å­—'}), 400

        # åŸ·è¡Œåˆ†æ
        result = detector_instance.analyze(full_text)
        if 'error' in result:
            return jsonify(result), 500

        return jsonify(result), 200

    except Exception as e:
        print(f"âŒ åˆ†ææ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ï¼š{e}")
        return jsonify({'error': f'ä¼ºæœå™¨å…§éƒ¨éŒ¯èª¤: {str(e)}'}), 500

if __name__ == '__main__':
    # æœ¬åœ°æ¸¬è©¦ç”¨ï¼›Render æœƒç”¨ gunicorn å•Ÿå‹•ï¼š`gunicorn --bind 0.0.0.0:$PORT app:app`
    app.run(debug=True, host='0.0.0.0', port=5000)
